// Copyright (c) 2019 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:projectid: okd
:page-layout: guide-multipane
:page-duration: 45 minutes
:page-releasedate: 2019-09-11
:page-description: Explore how to deploy microservices on an OKD cluster using a virtual machine with Minishift. 
:page-tags: ['Kubernetes', 'Docker', 'Cloud'] 
:page-permalink: /guides/{projectid}
:page-related-guides: ['cloud-openshift', 'kubernetes-intro', 'kubernetes-microprofile-config', 'kubernetes-microprofile-health', 'istio-intro']
:common-includes: https://raw.githubusercontent.com/OpenLiberty/guides-common/master
:source-highlighter: prettify
:page-seo-title: Deploying microservices on an OKD cluster using Minishift
:page-seo-description: A tutorial on how to deploy microservices using a VM with Minishift. 
:guide-author: Open Liberty
= Deploying microservices on an OKD cluster using Minishift

[.hidden]
NOTE: This repository contains the guide documentation source. To view the guide in published form, view it on the https://openliberty.io/guides/{projectid}.html[Open Liberty website^].

Explore how to deploy microservices on an OKD cluster using a virtual machine with Minishift. 

// *********************************************************************************************

//TODO What you'll learn
== What you'll learn 

You will learn how to quickly deploy an Origin Community Distribution of Kubernetes (OKD) cluster on an all-in-one virtual machine with Minishift. Then, you will deploy two simple REST microservices on an Open Liberty container to the running cluster.

OKD, formerly known as OpenShift Origin, is the upsteam open-source project for all OpenShift products. OKD is a Kubernetes-based platform with added functionality. OKD streamlines the DevOps process by providing an intuitive development pipeline, it also provides integration with multiple tools to make the deployment and management of cloud applications easier. To learn more about the different platforms that Red Hat OpenShift offers, check out the https://docs.openshift.com[official OpenShift documentation^]. To learn how to deploy microservices to OpenShift Online, check out the https://openliberty.io/guides/cloud-openshift.html[Deploying microservices to OpenShift^] guide.

Kubernetes is an open source container orchestrator that automates many tasks that are involved in deploying, managing, and scaling containerized applications. If you would like to learn more about Kubernetes, check out the https://openliberty.io/guides/kubernetes-intro.html[Deploying microservices to Kubernetes^] guide.

Using Maven, you will build a simple microservice, called `system`, that collects basic system properties from your system and displays them on an endpoint that you can access in your web browser. Then, you will build another microservice, `inventory` that will interact with the `system` microservice, and learn how to deploy both to the cluster and establish communication between them.

You will use Minishift, an all-in-one virtual machine based on Minikube. Similar to how Minikube makes it easy to deploy a local Kubernetes cluster locally, Minishift allows a quick and easy environment for application development that supports all OKD features.

// *********************************************************************************************

//TODO Additional Prerequisites
== Additional Prerequisites 

- *Minishift:* Minishift allows you to easily try OKD by running a VM with a single-node cluster. You can use Minishift with any OS, making it a convenient and flexible tool for testing and development. For installation instructions, refer to the official https://docs.okd.io/latest/minishift/index.html[OKD Minishift documentation^].

To verify that Minishift is installed correctly, run the following command:

[role=command]
```
minishift version
```

The output is similar to:

[role="no_copy"]
----
minishift v1.34.1+c2ff9cb
----

- *Docker:* Docker is a containerization software for building the containers that you will eventually deploy onto the OKD cluster. For installation instructions, refer to the official https://docs.docker.com/install/[Docker documentation^]. To learn how to use Docker for iterative development with Open Liberty, check out the https://openliberty.io/guides/docker.html[Using Docker containers to develop microservices^] and the https://openliberty.io/guides/containerize.html[Containerizing microservices^] guides.

// *********************************************************************************************

//TODO Getting Started
//== Getting Started

[role=command]
include::{common-includes}/gitclone.adoc[]

// *********************************************************************************************

//TODO Starting Minishift
== Starting Minishift

=== Deploying the cluster

Ensure you have Docker installed on your machine, then run the following command to start Minishift and deploy the cluster:

[role=command]
```
minishift start
```

=== Logging in to the cluster

If the cluster started successfully, you'll see the following output:

[role="no_copy"]
----
Server Information ...
OpenShift server started.

The server is accessible via web console at:
    https://192.168.99.103:8443/console
----

You can run through the development cycle using OpenShift's intuitive web console through the URL provided in the command output of the `minishift start` command. The web console provides a user friendly GUI alternative to their CLI tools, however this guide will continue with the CLI tools. You can also run the following command to open the web console:

[role=command]
```
minishift console
```

You can add the `--url` flag at the end of the `minishift console` command to only display the URL. 

Log in with the following credentials:

[role="no_copy"]
----
User:     developer
Password: [a password value]
----

You can confirm your credentials by running the `oc whoami` command, you will get `developer` as your output.

Next, create a new OpenShift project with the following command:

[role=command]
```
oc new-project [project-name]
```

You are now ready to build and deploy a microservice.

// *********************************************************************************************

//TODO Deploying a microservice
== Deploying a microservice

//file 0
Dockerfile
[source, Text, linenums, role="code_column"]
----
include::finish/system/Dockerfile[]
----

A simple microservice named `system` will be packaged, containerized, and deployed onto the OKD cluster. The `system` microservice will collect the JVM properties of the host machine that accessed the web server, and will output the properties in a JSON format.

=== Building the microservice

Navigate to the start directory. The source code of the system and inventory microservices are located at the `system` and `inventory` directories respectively. Focus on the `system` microservice first, and you will visit the `inventory` microservice later. 

In the `start` directory, run the following command to package both microservices:

[role=command]
```
mvn package
```

The `mvn package` command will compile, verify, and build the project. The resulting compiled code will be packaged into a `tar.gz` archive which can be found at `system/target/system.tar.gz` and `inventory/target/inventory.tar.gz`.

=== Containerizing the microservice

==== Re-using the Docker daemon

To speed up the development process, the built-in Minishift Docker daemon can be re-used to avoid needing to build a Docker registry on the the host machine. To re-use the Docker daemon, run the following command:

[role=command]
```
minishift docker-env
```

The result of the command is a list of bash environment variable exports that will configure your environment to re-use the Docker daemon inside the single Minishift VM instance. The commands differ based on your OS and environment, but you will get an output similar to the following:

[role=no_copy]
----
export DOCKER_TLS_VERIFY="1"
export DOCKER_HOST="tcp://192.168.99.103:2376"
export DOCKER_CERT_PATH="/Users/maihameed@ibm.com/.minishift/certs"
# Run this command to configure your shell:
# eval $(minishift docker-env)
----

Run the given `eval` command to configure your environment:

[role=command]
```
eval $(minishift docker-env)
```

==== Building the Docker image

Now that the environment is set up, ensure that you are in the `start` directory and run the following command to build a Docker image:

[role=command]
```
docker build -t system system/
```

The command builds an image named `system` from the [hotspot file=0]`Dockerfile` found in the `system` directory. To verify that the images are built, run the following command to list all local Docker images:

[role=command]
```
docker images
```

Your `system` image should appear in the list of all Docker images:

[role=no_copy]
----
REPOSITORY             TAG                 IMAGE ID            CREATED             SIZE
system                 latest              e8a8393e9364        2 minutes ago       399MB
----

==== Accessing the internal registry

In order to run the microservice on the OKD cluster, you need to push the microservice image into a container image registry. You will use OpenShiftâ€™s integrated container image registry called OpenShift Container Registry (OCR). First, you must authenticate your Docker client to your OCR. Start by running the login command:

[role=command]
```
docker login -u `oc whoami` -p `oc whoami -t` `oc registry info`
```

Now you must tag and push your `system` microservice to the internal registry so that it is accessible for deployment. Run the following command to tag your microservice:

[role=command]
```
docker tag system `oc registry info`/`oc project -q`/system
```

Your newly tagged image should appear in the list of all Docker images:

[role=no_copy]
----
REPOSITORY                             TAG                 IMAGE ID            CREATED             SIZE
system                                 latest              e8a8393e9364        2 minutes ago       399MB
172.30.1.1:5000/my-project/system      latest              e8a8393e9364        2 minutes ago       399MB
----

Now push your newly tagged image to the internal registry with the following command:

[role=command]
```
docker push `oc registry info`/`oc project -q`/system
```

The microservice is now ready for deployment.

=== Deploying the microservice

Now that your Docker images are built, deploy them using a resource configuration file. Since OKD is built on top of Kubernetes, it supports the same concepts and deployment strategies. The OpenShift `oc` CLI tool supports most of the same commands as the Kubernetes `kubectl` tool. To learn more aboout Kubernetes and resource configuration files, check out the https://openliberty.io/guides/kubernetes-intro.html[Deploying microservices to Kubernetes^] guide.

[role='code_command hotspot file=0', subs='quotes']
----
#Create the `deploy.yaml` configuration file.#
`deploy.yaml`
----

The configuration file outlines a [hotspot=deployment file=0]`deployment` resource which will create and deploy a [hotspot=image file=0]`container` that will run the Docker-formatted image provided in the [hotspot=image file=0]`image` field. The [hotspot=image file=0]`image` field should point to your newly pushed image. 

//file 0
deploy.yaml
[source, yaml, linenums, role='code_column hide_tags=everythingButSystemDeployment']
----
include::finish/deploy.yaml[]
----

Run the following command to view the image stream:

[role=command]
```
oc get imagestream
```

You should find your newly pushed image:

[role=no_copy]
----
NAME      DOCKER REPO                         TAGS      UPDATED
system    172.30.1.1:5000/my-project/system   latest    15 hours ago
----

The OpenShift image stream displays all the Docker-formatted container images pushed to the internal registry. You can configure builds and deployments to trigger when an image is updated. 

[role="code_command hotspot file=0", subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
The [hotspot=image]`image` is the name and tag of the container image that you want to use for the system container. Update the system 
[hotspot=image]`image` field to the image link found in the `DOCKER REPO` column of the image stream.

//file 0
deploy.yaml
[source, yaml, linenums, role='code_column hide_tags=everythingButSystemDeployment']
----
include::finish/deploy.yaml[]
----

//file 1
deploy.yaml
[source, yaml, linenums, role='code_column hide_tags=everythingButSystemDeploymentAndService']
----
include::finish/deploy.yaml[]
----

Once updated, run the following command to apply the configuration file and create your OpenShift resource:

[role=command]
```
oc apply -f deploy.yaml
```

You will get an output similar to the following:

[role=no_copy]
----
deployment.apps/system-deployment created
----

Run the following command to view your pods:

[role=command]
```
oc get pods
```

Ensure that your `system-deployment` pod is `RUNNING`:

[role=no_copy]
----
NAME                                 READY     STATUS    RESTARTS   AGE
system-deployment-768f95cf8f-fnjjj   1/1       Running   0          5m
----

Run the following command to get more details on your pod:

[role=command]
```
oc describe pod system-deployment
```

The events log is useful in debugging any issues that may arise:

[role=no_copy]
----
Events:
  Type    Reason     Age   From                Message
  ----    ------     ----  ----                -------
  Normal  Scheduled  1d    default-scheduler   Successfully assigned my-project/system-deployment-768f95cf8f-fnjjj to localhost
  Normal  Pulling    1d    kubelet, localhost  pulling image "172.30.1.1:5000/my-project/system"
  Normal  Pulled     1d    kubelet, localhost  Successfully pulled image "172.30.1.1:5000/my-project/system"
  Normal  Created    1d    kubelet, localhost  Created container
  Normal  Started    1d    kubelet, localhost  Started container
----

The container is deployed successfully, however it is isolated and can not be accessed for requests. A service needs to be created to expose your deployment so that you can make requests to your container. Update your [hotspot file=0]`deploy.yaml` file to include a service resource. 

[role="code_command hotspot file=1", subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
Update the configuration file to include the [hotspot=systemService]`service` resource.

//file 1
deploy.yaml
[source, yaml, linenums, role="code_column hide_tags=everythingButSystemDeploymentAndService"]
----
include::finish/deploy.yaml[]
----

To update your resources, run the following command:

[role=command]
```
oc apply -f deploy.yaml
```

Notice that the cluster will only pick up on any changes, and will not tear down and rebuild the deployment if it has been unchanged:

[role=no_copy]
----
deployment.apps/system-deployment unchanged
service/system-service created
----

Finally, expose the service using a route, so that external users can access the microservice through a host name, such as `www.mywebapp.com`. To expose your service, run the following command:

[role=command]
```
oc expose service system-service
```

You can view all of your routes with the following command:

[role=command]
```
oc get routes
```

You will get an output similar to:

[role=no_copy]
----
NAME             HOST/PORT                                         PATH      SERVICES         PORT      TERMINATION   WILDCARD
system-service   system-service-my-project.192.168.99.103.nip.io             system-service   9080                    None
----

Access your microservice through the host name provided in the output, by visiting the following URL `https://[host-name]/system/properties`, or running the following command, ensuring to replace `[host-name]` with the proper host name provided by the `oc get routes` command.

[role=command]
```
curl https://[host-name]/system/properties
```

You can also add the route resource to your resource configuration file to reduce the number of steps in the deployment process. 

[role="code_command hotspot file=2", subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
Update the configuration file to include the [hotspot=systemRoute]`route` resource.

//file 2
deploy.yaml
[source, yaml, linenums, role="code_column hide_tags=inventoryResources"]
----
include::finish/deploy.yaml[]
----

// *********************************************************************************************

//TODO Deploying a second microservice
== Deploying a second microservice

//file 0
deploy.yaml
[source, yaml, linenums, role="code_column"]
----
include::hotspots/deploy.yaml[]
----

Now that the `system` microservice is running, you will now package and deploy the `inventory` microservice, which adds the properties from the `system` microservice to the inventory. This demonstrates how communication can be established between pods inside a cluster.

=== Containerizing the microservice

Since the `inventory` microservice has already been packaged, run the following command to use the `inventory` Dockerfile to create an image:

[role=command]
```
docker build -t inventory inventory/
```

Run the following commands to tag and push your `inventory` microservice to the internal registry:

[role=command]
```
docker tag inventory `oc registry info`/`oc project -q`/inventory
docker push `oc registry info`/`oc project -q`/inventory
```

The microservice is now ready for deployment.

=== Deploying the microservice

You can use the same [hotspot file=0]`deploy.yaml` configuration file to deploy multiple microservices. Update the configuration file to include the deployment, service, and route resources for your `inventory` microservice.

[role="code_command hotspot file=0", subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
Update the configuration file to add the [hotspot=inventoryResources file=0]`inventory` resources, making sure to update the inventory [hotspot=inventoryImage file=0]`image` field with the appropriate image link.

Now run the following command to allow the cluster to pick up the new changes:

[role=command]
```
oc apply -f deploy.yaml
```

Run the following command to get the host name of the newly exposed `inventory` service:

[role=command]
```
oc get route inventory-route
```

Visit the following link, `https://[host-name]/inventory/systems` or run the following `curl` command to view the current inventory, ensuring that you replace the `[host-name]` with your appropriate host name:

[role=command]
```
curl https://[host-name]/inventory/systems
```

You will see the following response, note that it has been properly formatted in this guide for easier readability:

[role=no_copy]
----
{
    "systems": [],
    "total": 0
}
----

Note that since this is a fresh deployment, there are no saved systems in the inventory. Visit the following link, `https://[host-name]/inventory/systems/system-service` or run the following command to allow the `inventory` microservice to access the `system` microservice and save the system result in the inventory:

[role=command]
```
curl https://[host-name]/inventory/systems/system-service
```

You will receive your JVM system properties as a response. Visit the following link, `https://[host-name]/inventory/systems` or run the following command to recheck the inventory:

[role=command]
```
curl https://[host-name]/inventory/systems
```

You will see the following response:

[role=no_copy]
----
{
    "systems": [
        {
            "hostname": "system-service",
            "properties": {
                "os.name": "Linux",
                "user.name": "unknown"
            }
        }
    ],
    "total": 1
}
----

Notice that the system count incremented by 1, and provided a list of a few key fields retrieved from the system response.