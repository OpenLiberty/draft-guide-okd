// Copyright (c) 2019 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:projectid: okd
:page-layout: guide-multipane
:page-duration: 1 hour
:page-releasedate: 2019-12-13
:page-description: Explore how to deploy microservices on an OKD cluster using a virtual machine with Minishift. 
:page-tags: ['Kubernetes', 'Docker', 'Cloud'] 
:page-permalink: /guides/{projectid}
:page-related-guides: ['cloud-openshift', 'istio-intro', 'microprofile-istio-retry-fallback', 'kubernetes-intro', 'containerize']
:common-includes: https://raw.githubusercontent.com/OpenLiberty/guides-common/master
:source-highlighter: prettify
:page-seo-title: Deploying microservices on an OKD cluster using Minishift
:page-seo-description: A tutorial on how to deploy microservices using a VM with Minishift. 
:guide-author: Open Liberty
= Deploying microservices on an OKD cluster using Minishift

[.hidden]
NOTE: This repository contains the guide documentation source. To view the guide in published form, view it on the https://openliberty.io/guides/{projectid}.html[Open Liberty website^].

Explore how to utilize Minishift to deploy microservices to an Origin Community Distribution of Kubernetes (OKD) cluster. 

// *********************************************************************************************

== What you'll learn 

You will learn how to deploy two simple microservices with Open Liberty to an OKD cluster running in Minishift.

OKD, formerly known as OpenShift Origin, is the upsteam open-source project for all OpenShift products. OKD is a Kubernetes-based platform with added
functionality. If you would like to learn more about Kubernetes, check out the 
https://openliberty.io/guides/kubernetes-intro.html[Deploying microservices to Kubernetes^] guide. OKD streamlines the DevOps process by providing an 
intuitive development pipeline. It also provides integration with multiple tools to make the deployment and management of cloud applications easier. To 
learn more about the different platforms that Red Hat OpenShift offers, check out the https://docs.openshift.com[official OpenShift documentation^]. To 
learn how to deploy microservices to OpenShift Online, check out the https://openliberty.io/guides/cloud-openshift.html[Deploying microservices to OpenShift^] 
guide.

Using Maven, you will build a simple microservice called `system` that collects basic system properties from your system. Then, you will build another 
microservice, `inventory` that will interact with the `system` microservice, and learn how to deploy both to the cluster and establish communication between 
them.

You will use Minishift, an all-in-one virtual machine built on top of Minikube. Similar to how Minikube makes it easy to deploy a local Kubernetes cluster 
locally, Minishift allows a quick and easy environment for application development that supports all OKD features.

// *********************************************************************************************

== Additional Prerequisites 

- *Minishift:* Minishift allows you to easily try OKD by running a VM with a single-node cluster. You can use Minishift with any OS, making it a convenient 
and flexible tool for testing and development. For installation instructions, refer to the official 
https://docs.okd.io/latest/minishift/index.html[OKD Minishift documentation^].

To verify that Minishift is installed correctly, run the following command:

[role=command]
```
minishift version
```

The output is similar to:

[role="no_copy"]
----
minishift v1.34.1+c2ff9cb
----

- *Docker:* Docker is a containerization software for building the containers that you will eventually deploy onto the OKD cluster. For installation 
instructions, refer to the official https://docs.docker.com/install/[Docker documentation^].

// *********************************************************************************************

//== Getting Started

[role=command]
include::{common-includes}/gitclone.adoc[]

// *********************************************************************************************

== Starting Minishift

=== Deploying the cluster

Run the following command to start Minishift and create the OKD cluster:

[role=command]
```
minishift start
```

=== Logging in to the cluster

If the cluster started successfully, you'll see the following output:

[role="no_copy"]
----
Server Information ...
OpenShift server started.

The server is accessible via web console at:
    https://192.168.99.103:8443/console
----

To interact with the OpenShift cluster, you will need to use the `oc` command. Minishift already includes the `oc` binary. To use the `oc` commands, 
run the following command to configure your PATH to include the binary:

[role=command]
```
minishift oc-env
```

The resulting output differ based on your OS and environment, but you will get an output similar to the following:

include::{common-includes}/os-tabs.adoc[]
[.tab_content.linux_section]
--
[role="no_copy"]
----
export PATH="/root/.minishift/cache/oc/v3.11.0/linux:$PATH"
# Run this command to configure your shell:
# eval $(minishift oc-env)
----

Run the appropriate command to configure your environment:

[role=command]
```
eval $(minishift oc-env)
```
--

[.tab_content.mac_section]
--
[role="no_copy"]
----
export PATH="/Users/guidesbot@ibm.com/.minishift/cache/oc/v3.11.0/darwin:$PATH"
# Run this command to configure your shell:
# eval $(minishift oc-env)
----

Run the appropriate command to configure your environment:

[role=command]
```
eval $(minishift oc-env)
```
--

[.tab_content.windows_section] 
--
[role="no_copy"]
----
SET PATH=C:\Users\guides-bot\.minishift\cache\oc\v3.11.0\windows;%PATH%
REM Run this command to configure your shell:
REM     @FOR /f "tokens=*" %i IN ('minishift oc-env') DO @call %i
----

Run the appropriate command to configure your environment:

[role=command]
```
@FOR /f "tokens=*" %i IN ('minishift oc-env') DO @call %i
```
--

You can run through the development cycle using OpenShift's intuitive web console through the URL provided in the command output of the `minishift start` 
command. The web console provides a user friendly GUI alternative to their CLI tools, however this guide will continue with the CLI tools. You can also run 
the following command to open the web console:

[role=command]
```
minishift console
```

Log in with the following credentials:

[role="no_copy"]
----
User:     developer
Password: [any value]
----

You can confirm your credentials by running the `oc whoami` command, you will get `developer` as your output.

Next, create a new OpenShift project with the following command:

[role=command]
```
oc new-project [project-name]
```

You are now ready to build and deploy a microservice.

// *********************************************************************************************

== Building the system microservice

//file 0
Dockerfile
[source, Text, linenums, role="code_column"]
----
include::finish/system/Dockerfile[]
----

A simple microservice named `system` will be packaged, containerized, and deployed onto the OKD cluster. The `system` microservice will collect the JVM 
properties of the host machine.

Navigate to the `start` directory. The source code of the system and inventory microservices are located at the `system` and `inventory` directories 
respectively. Focus on the `system` microservice first, and you will visit the `inventory` microservice later. 

In the `start` directory, run the following command to package the `system` microservice:

[role=command]
```
mvn -pl system package
```

The `mvn package` command will compile, verify, and build the project. The resulting compiled code will be packaged into a `war` web archive which can be 
found at `system/target/system.war`. The archive contains all the configuration files, as well as the application needed to run the microservice on an 
Open Liberty server, and is now ready to be injected into a Docker container for deployment.

== Containerizing the system microservice

=== Re-using the Docker daemon

To speed up the development process, the built-in Minishift Docker daemon can be re-used to avoid needing to build a Docker registry on the the host machine. 
To re-use the Docker daemon, run the following command:

[role=command]
```
minishift docker-env
```

The result of the command is a list of bash environment variable exports that will configure your environment to re-use the Docker daemon inside the single 
Minishift VM instance. The commands differ based on your OS and environment, but you will get an output similar to the following:

include::{common-includes}/os-tabs.adoc[]
[.tab_content.mac_section.linux_section]
--
[role=no_copy]
----
export DOCKER_TLS_VERIFY="1"
export DOCKER_HOST="tcp://192.168.99.103:2376"
export DOCKER_CERT_PATH="/Users/guidesbot@ibm.com/.minishift/certs"
# Run this command to configure your shell:
# eval $(minishift docker-env)
----

Run the given `eval` command to configure your environment:

[role=command]
```
eval $(minishift docker-env)
```
--

[.tab_content.windows_section]
--
[role=no_copy]
----
SET DOCKER_TLS_VERIFY=1
SET DOCKER_HOST=tcp://9.26.69.218:2376
SET DOCKER_CERT_PATH=C:\Users\maihameed\.minishift\certs
REM Run this command to configure your shell:
REM     @FOR /f "tokens=*" %i IN ('minishift docker-env') DO @call %i
----

Run the given `@FOR` command to configure your environment:

[role=command]
```
@FOR /f "tokens=*" %i IN ('minishift docker-env') DO @call %i
```
--

=== Building the Docker image

Now that the environment is set up, ensure that you are in the `start` directory and run the following command to build the `system` Docker image:

[role=command]
```
docker build -t system system/
```

The command builds an image named `system` from the [hotspot file=0]`Dockerfile` provided in the `system` directory. To verify that the images are built, run 
the following command to list all local Docker images:

[role=command]
```
docker images
```

Your `system` image should appear in the list of all Docker images:

[role=no_copy]
----
REPOSITORY             TAG                 IMAGE ID            CREATED             SIZE
system                 latest              e8a8393e9364        2 minutes ago       399MB
----

=== Accessing the internal registry

In order to run the microservice on the OKD cluster, you need to push the microservice image into a container image registry. You will use OpenShift’s 
integrated container image registry called OpenShift Container Registry (OCR). First, you must authenticate your Docker client to your OCR. Start by running 
the login command:

include::{common-includes}/os-tabs.adoc[]
[.tab_content.mac_section.linux_section]
--
[role=command]
```
echo $(oc whoami -t) | docker login -u developer --password-stdin $(oc registry info)
```
--

[.tab_content.windows_section]
--
Because the Windows command prompt doesn’t support the command substitution that is displayed for Mac and Linux, run the following commands: 
[role=command]
```
oc whoami
oc whoami -t
oc registry info
```

Replace the square brackets in the following `docker login` command with the results from the previous commands:
[role=command]
```
docker login -u [oc whoami] -p [oc whoami -t] [oc registry info]
```
--

Now you must tag and push your `system` microservice to the internal registry so that it is accessible for deployment. Run the following command to tag your 
microservice:

include::{common-includes}/os-tabs.adoc[]
[.tab_content.mac_section.linux_section]
--
[role=command]
```
docker tag system $(oc registry info)/$(oc project -q)/system
```
--

[.tab_content.windows_section]
--
Because the Windows command prompt doesn’t support the command substitution that is displayed for Mac and Linux, run the following commands:  
[role=command]
```
oc registry info
oc project -q
```

Replace the square brackets in the following `docker tag` command with the results from the previous commands:
[role=command]
```
docker tag system [oc registry info]/[oc project -q]/system
```
--

Your newly tagged image should appear in the list of all Docker images:

[role=no_copy]
----
REPOSITORY                             TAG                 IMAGE ID            CREATED             SIZE
system                                 latest              e8a8393e9364        2 minutes ago       399MB
172.30.1.1:5000/my-project/system      latest              e8a8393e9364        2 minutes ago       399MB
----

Now push your newly tagged image to the internal registry with the following command:

include::{common-includes}/os-tabs.adoc[]
[.tab_content.mac_section.linux_section]
--
[role=command]
```
docker push $(oc registry info)/$(oc project -q)/system
```
--

[.tab_content.windows_section]
--
Because the Windows command prompt doesn’t support the command substitution that is displayed for Mac and Linux, run the following commands:
[role=command]
```
oc registry info
oc project -q
```

Replace the square brackets in the following `docker push` command with the results from the previous commands:
[role=command]
```
docker push [oc registry info]/[oc project -q]/system
```
--

The microservice is now ready for deployment.

== Deploying the system microservice

Now that the `system` Docker image is built, deploy it using a resource configuration file. Since OKD is built on top of Kubernetes, it supports the same 
concepts and deployment strategies. The OpenShift `oc` CLI tool supports most of the same commands as the Kubernetes `kubectl` tool. To learn more aboout 
Kubernetes and resource configuration files, check out the https://openliberty.io/guides/kubernetes-intro.html[Deploying microservices to Kubernetes^] guide.

The provided [hotspot file=0]`deploy.yaml` configuration file outlines a [hotspot=deployment file=0]`deployment` resource which will create and deploy a 
[hotspot=container file=0]`container` that will run the Docker-formatted image provided in the [hotspot=image file=0]`image` field. The 
[hotspot=image file=0]`image` field should point to your newly pushed image. 

//file 0
deploy.yaml
[source, yaml, linenums, role='code_column hide_tags=everythingButSystemDeployment']
----
include::finish/deploy.yaml[]
----

Run the following command to view the image stream:

[role=command]
```
oc get imagestream
```

You should find your newly pushed image:

[role=no_copy]
----
NAME      DOCKER REPO                         TAGS      UPDATED
system    172.30.1.1:5000/my-project/system   latest    15 hours ago
----

The OpenShift image stream displays all the Docker-formatted container images pushed to the internal registry. You can configure builds and deployments to 
trigger when an image is updated. 

[role="code_command hotspot file=0", subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
The [hotspot=image file=0]`image` is the name and tag of the container image that you want to use for the system container. Update the system 
[hotspot=image file=0]`image` field to the image link found in the `DOCKER REPO` column of the image stream.

Once updated, run the following command to apply the configuration file and create your OpenShift resource:

[role=command]
```
oc apply -f deploy.yaml
```

You will get an output similar to the following:

[role=no_copy]
----
deployment.apps/system-deployment created
----

Run the following command to view your pods:

[role=command]
```
oc get pods
```

Ensure that your `system-deployment` pod is `Running`:

[role=no_copy]
----
NAME                                 READY     STATUS    RESTARTS   AGE
system-deployment-768f95cf8f-fnjjj   1/1       Running   0          5m
----

Run the following command to get more details on your pod:

[role=command]
```
oc describe pod system-deployment
```

The events log is useful in debugging any issues that may arise:

[role=no_copy]
----
Events:
  Type    Reason     Age   From                Message
  ----    ------     ----  ----                -------
  Normal  Scheduled  1d    default-scheduler   Successfully assigned my-project/system-deployment-768f95cf8f-fnjjj to localhost
  Normal  Pulling    1d    kubelet, localhost  pulling image "172.30.1.1:5000/my-project/system"
  Normal  Pulled     1d    kubelet, localhost  Successfully pulled image "172.30.1.1:5000/my-project/system"
  Normal  Created    1d    kubelet, localhost  Created container
  Normal  Started    1d    kubelet, localhost  Started container
----

The container is deployed successfully, however it is isolated and cannot be accessed for requests. A service needs to be created to expose your deployment 
so that you can make requests to your container. Update your [hotspot file=1]`deploy.yaml` file to include a service resource. 

[role='code_command hotspot file=1', subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
Update the configuration file to include the [hotspot=systemService file=1]`service` resource.

//file 1
deploy.yaml
[source, yaml, linenums, role='code_column hide_tags=everythingButSystemDeploymentAndService']
----
include::finish/deploy.yaml[]
----

Now you have to expose the service using a route so that external users can access the microservice through a host name. Update 
your [hotspot file=1]`deploy.yaml` file to include a route resource.

[role='code_command hotspot file=2', subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
Update the configuration file to include the [hotspot=systemRoute file=2]`route` resource.

//file 2
deploy.yaml
[source, yaml, linenums, role='code_column hide_tags=inventoryResources']
----
include::finish/deploy.yaml[]
----

To update your resources, run the following command:

[role=command]
```
oc apply -f deploy.yaml
```

Notice that the cluster will only pick up on any changes, and will not tear down and rebuild the deployment if it has been unchanged:

[role=no_copy]
----
deployment.apps/system-deployment unchanged
service/system-service created
route/system-route created
----

You can view all of your routes with the following command:

[role=command]
```
oc get routes
```

You will get an output similar to:

[role=no_copy]
----
NAME             HOST/PORT                                         PATH      SERVICES         PORT      TERMINATION   WILDCARD
system-route     system-route-my-project.192.168.99.103.nip.io               system-service   <all>                   None
----

Access your microservice through the hostname provided in the output, by visiting the following URL `http://[hostname]/system/properties`, or running the 
following command, ensuring to replace `[hostname]` with the proper host name provided by the `oc get routes` command.

[role=command]
```
curl http://[hostname]/system/properties
```

// *********************************************************************************************

== Deploying the inventory microservice

//file 0
deploy.yaml
[source, yaml, linenums, role="code_column"]
----
include::finish/deploy.yaml[]
----

Now that the `system` microservice is running, you will now package and deploy the `inventory` microservice, which adds the properties from the `system` 
microservice to the inventory. This demonstrates how communication can be established between pods inside a cluster.

=== Building the microservice

In the `start` directory, run the following command to package the `inventory` microservice:

[role=command]
```
mvn -pl inventory package
```

=== Containerizing the microservice

Run the following command to use the `inventory` Dockerfile to create an image:

[role=command]
```
docker build -t inventory inventory/
```

include::{common-includes}/os-tabs.adoc[]
[.tab_content.mac_section.linux_section]
--
Run the following command to tag your microservice:
[role=command]
```
docker tag inventory $(oc registry info)/$(oc project -q)/inventory
```

Now push your newly tagged image to the internal registry with the following command:
[role=command]
```
docker push $(oc registry info)/$(oc project -q)/inventory
```
--

[.tab_content.windows_section]
--
Because the Windows command prompt doesn’t support the command substitution that is displayed for Mac and Linux, run the following commands:
[role=command]
```
oc registry info
oc project -q
```

Replace the square brackets in the following command with the results from the previous commands to tag your microservice:
[role=command]
```
docker tag inventory [oc registry info]/[oc project -q]/inventory
```

Run the following command to push your microservice, ensuring to replace the square brackets:
[role=command]
```
docker push [oc registry info]/[oc project -q]/inventory
```
--

The microservice is now ready for deployment.

=== Deploying the microservice

You can use the same [hotspot file=0]`deploy.yaml` configuration file to deploy multiple microservices. Update the configuration file to include the 
deployment, service, and route resources for your `inventory` microservice.

[role="code_command hotspot file=0", subs="quotes"]
----
#Update the `deploy.yaml` file.#
`deploy.yaml`
----
[role="edit_command_text"]
Update the configuration file to add the [hotspot=inventoryResources file=0]`inventory` resources, making sure to update the inventory 
[hotspot=inventoryImage file=0]`image` field with the appropriate image link found in the `DOCKER REPO` column of the `oc get imagestream` command.

Now run the following command to allow the cluster to pick up the new changes:

[role=command]
```
oc apply -f deploy.yaml
```

Run the following command to get the host name of the newly exposed `inventory` service:

[role=command]
```
oc get route inventory-route
```

You will get an output similar to:

[role=no_copy]
----
NAME              HOST/PORT                                    PATH      SERVICES            PORT      TERMINATION   WILDCARD
inventory-route   inventory-route-myproject.127.0.0.1.nip.io             inventory-service   <all>                   None
----

Visit the following link, `http://[host-name]/inventory/systems` or run the following `curl` command to view the current inventory, ensuring that you 
replace the `[host-name]` with your appropriate host name:

[role=command]
```
curl http://[host-name]/inventory/systems
```

You will see the following response, note that it has been properly formatted in this guide for easier readability:

[role=no_copy]
----
{
    "systems": [],
    "total": 0
}
----

Note that since this is a fresh deployment, there are no saved systems in the inventory. Visit the following link, 
`http://[host-name]/inventory/systems/system-service` or run the following command to allow the `inventory` microservice to access the `system` microservice 
and save the system result in the inventory:

[role=command]
```
curl http://[host-name]/inventory/systems/system-service
```

You will receive your JVM system properties as a response. Visit the following link, `http://[host-name]/inventory/systems` or run the following command to 
recheck the inventory:

[role=command]
```
curl http://[host-name]/inventory/systems
```

You will see the following response:

[role=no_copy]
----
{
    "systems": [
        {
            "hostname": "system-service",
            "properties": {
                "os.name": "Linux",
                "user.name": "unknown"
            }
        }
    ],
    "total": 1
}
----

Notice that the system count incremented by 1, and provided a list of a few key fields retrieved from the system response.

== Testing the microservices

pom.xml
[source, xml, linenums, role='code_column']
----
include::finish/inventory/pom.xml[]
----

A few tests are included for you to test the basic functions of the microservices. If a test failure occurs, then you might have introduced a bug 
into the code. To run the tests, wait for all pods to be in the ready state before you proceed further. The default properties that are defined in 
the [hotspot file=0]`pom.xml` file are:

[cols="15, 100", options="header"]
|===
| *Property*                                            | *Description*
| [hotspot=systemIP]`system.ip`                         | IP or hostname of the `system-service` Kubernetes Service
| [hotspot=inventoryIP]`inventory.ip`                   | IP or hostname of the `inventory-service` Kubernetes Service
|===

Use the following command to run the integration tests against your running cluster:

include::{common-includes}/os-tabs.adoc[]
[.tab_content.windows_section]
--
Substitute `[system-route-hostname]` and `[inventory-route-hostname]` with the appropriate values found by running the `oc get routes` command

[role=command]
```
mvn verify -Ddockerfile.skip=true -Dsystem.ip=[system-route-hostname] -Dinventory.ip=[inventory-route-hostname]
```
--
[.tab_content.mac_section.linux_section]
--
[role=command]
```
mvn verify -Ddockerfile.skip=true \
-Dsystem.ip=$(oc get route system-route -o=jsonpath='{.spec.host}') \
-Dinventory.ip=$(oc get route inventory-route -o=jsonpath='{.spec.host}')
```
--

- The `dockerfile.skip` parameter is set to `true` to skip building a new container image.
- The `system.ip` parameter is replaced with the appropriate hostname to access your system microservice.
- The `inventory.ip` parameter is replaced with the appropriate hostname to access your inventory microservice.

If the tests pass, you see an output for each service similar to the following example:

[source, role="no_copy"]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.system.SystemEndpointIT
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.673 sec - in it.io.openliberty.guides.system.SystemEndpointIT

Results:

Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
----

[source, role="no_copy"]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.inventory.InventoryEndpointIT
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.222 sec - in it.io.openliberty.guides.inventory.InventoryEndpointIT

Results:

Tests run: 4, Failures: 0, Errors: 0, Skipped: 0
----

== Tearing down the environment

When you no longer need your deployed microservices, you can use the same configuration file to delete them. Run the following command to delete your
deployments, systems, and routes:

[role=command]
```
oc delete -f deploy.yaml
```

To completely delete your Minishift VM, cluster, and all associated files run the following command:

[role=command]
```
minishift delete
```

To revert your Docker daemon back to its default settings, simply close the shell session.

== Great work! You're done!

You just deployed two microservices running in Open Liberty to an OKD cluster using the `oc` tool.

// Multipane
include::{common-includes}/attribution.adoc[subs="attributes"]
